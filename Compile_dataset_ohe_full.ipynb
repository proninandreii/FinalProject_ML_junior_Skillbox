{ "cells": [  {   "cell_type": "code",   "execution_count": 1,   "id": "initial_id",   "metadata": {    "collapsed": true,    "ExecuteTime": {     "end_time": "2023-12-22T10:46:28.903656Z",     "start_time": "2023-12-22T10:46:28.234861Z"    }   },   "outputs": [],   "source": [    "import pyarrow.parquet as pq\n",    "import matplotlib.pyplot as plt\n",    "import os\n",    "import pandas as pd\n",    "import tqdm\n",    "import pyarrow as pa\n",    "\n",    "import warnings\n",    "warnings.filterwarnings('ignore')\n",    "\n",    "plt.style.use('fivethirtyeight')"   ]  },  {   "cell_type": "code",   "execution_count": 2,   "outputs": [    {     "name": "stdout",     "output_type": "stream",     "text": [      "Обработка файла завершена.\n"     ]    }   ],   "source": [    "# Задаем данные\n",    "target_path = \"train_target.csv\"\n",    "path = 'train_data'\n",    "\n",    "target_df = pd.read_csv(target_path)\n",    "\n",    "print(f\"Обработка файла завершена.\")"   ],   "metadata": {    "collapsed": false,    "ExecuteTime": {     "end_time": "2023-12-22T10:46:29.052671Z",     "start_time": "2023-12-22T10:46:28.898375Z"    }   },   "id": "9bf6f0b5cb7a5323"  },  {   "cell_type": "markdown",   "source": [    "Все признаки, которые \"бинаризированы\" и \"закодированы\" имеют случайные числовые промежутки, поэтому к ним попробуем применить OneHotEncoding, а к признакам из binarized_columns просто агрегацию. "   ],   "metadata": {    "collapsed": false   },   "id": "47f9ca9ed66bd120"  },  {   "cell_type": "code",   "execution_count": 3,   "outputs": [],   "source": [    "def read_parquet_dataset_from_local(path_to_dataset: str, start_from: int = 0,\n",    "                                    num_parts_to_read: int = 2, columns=None, verbose=False) -> pd.DataFrame:\n",    "    \"\"\"\n",    "    читает num_parts_to_read партиций, преобразовывает их к pd.DataFrame и возвращает\n",    "    :param path_to_dataset: путь до директории с партициями\n",    "    :param start_from: номер партиции, с которой нужно начать чтение\n",    "    :param num_parts_to_read: количество партиций, которые требуется прочитать\n",    "    :param columns: список колонок, которые нужно прочитать из партиции\n",    "    :return: pd.DataFrame\n",    "    \"\"\"\n",    "\n",    "    res = []\n",    "    dataset_paths = sorted([os.path.join(path_to_dataset, filename) for filename in os.listdir(path_to_dataset)\n",    "                            if filename.startswith('train')])\n",    "    print(dataset_paths)\n",    "\n",    "    start_from = max(0, start_from)\n",    "    chunks = dataset_paths[start_from: start_from + num_parts_to_read]\n",    "    if verbose:\n",    "        print('Reading chunks:\\n')\n",    "        for chunk in chunks:\n",    "            print(chunk)\n",    "    for chunk_path in tqdm.tqdm_notebook(chunks, desc=\"Reading dataset with pandas\"):\n",    "        print('chunk_path', chunk_path)\n",    "        chunk = pd.read_parquet(chunk_path,columns=columns)\n",    "        res.append(chunk)\n",    "\n",    "    return pd.concat(res).reset_index(drop=True)"   ],   "metadata": {    "collapsed": false,    "ExecuteTime": {     "end_time": "2023-12-22T10:46:29.085443Z",     "start_time": "2023-12-22T10:46:29.055013Z"    }   },   "id": "b17705c08b6be95b"  },  {   "cell_type": "code",   "execution_count": 4,   "outputs": [],   "source": [    "def prepare_transactions_dataset(path_to_dataset: str, num_parts_to_preprocess_at_once: int = 1, num_parts_total: int=50,\n",    "                                 save_to_path=None, verbose: bool=False):\n",    "    \"\"\"\n",    "    возвращает готовый pd.DataFrame с признаками, на которых можно учить модель для целевой задачи\n",    "    path_to_dataset: str\n",    "        путь до датасета с партициями\n",    "    num_parts_to_preprocess_at_once: int\n",    "        количество партиций, которые будут одновременно держаться и обрабатываться в памяти\n",    "    num_parts_total: int\n",    "        общее количество партиций, которые нужно обработать\n",    "    save_to_path: str\n",    "        путь до папки, в которой будет сохранён каждый обработанный блок в .parquet-формате; если None, то не будет сохранён\n",    "    verbose: bool\n",    "        логирует каждую обрабатываемую часть данных\n",    "    \"\"\"\n",    "    preprocessed_frames = []\n",    "\n",    "    for step in tqdm.tqdm_notebook(range(0, num_parts_total, num_parts_to_preprocess_at_once),\n",    "                                   desc=\"Transforming transactions data\"):\n",    "        data_frame = read_parquet_dataset_from_local(path_to_dataset, step, num_parts_to_preprocess_at_once,\n",    "                                                             verbose=verbose)\n",    "\n",    "        #здесь должен быть препроцессинг данных\n",    "        data_frame['no_delinquencies'] = (data_frame['is_zero_loans530'].astype(bool) & data_frame['is_zero_loans3060'].astype(bool) &\n",    "                                          data_frame['is_zero_loans90'].astype(bool) & data_frame['is_zero_loans6090'].astype(bool) & \n",    "                                          data_frame['is_zero_loans5'].astype(bool)).astype(int)\n",    "        \n",    "        data_frame['total_delinquencies'] = data_frame['is_zero_loans530'] + data_frame['is_zero_loans3060'] + data_frame['is_zero_loans5'] + data_frame['is_zero_loans90'] + data_frame['is_zero_loans6090']\n",    "        \n",    "        binarized_columns = ['is_zero_loans5', 'is_zero_loans530', 'is_zero_loans3060', 'is_zero_loans6090', 'is_zero_loans90', 'is_zero_util', 'is_zero_over2limit', 'is_zero_maxover2limit', 'pclose_flag', 'fclose_flag', 'no_delinquencies']\n",    "        \n",    "        # Датафрейм содержащий в себе только действительно бинарные признаки\n",    "        df_second = data_frame[['id'] + binarized_columns].copy()\n",    "        \n",    "        # Датафрейм содержащий в себе все остальные признаки, которые пойдут в ohe\n",    "        df_first = data_frame.drop(binarized_columns, axis=1)\n",    "        \n",    "        feature_columns = list(df_first.columns.values)\n",    "        feature_columns.remove(\"id\")\n",    "        feature_columns.remove(\"rn\")\n",    "        \n",    "        # Кодируем датафрейм в ohe\n",    "        dummies = pd.get_dummies(df_first[feature_columns], columns=feature_columns)\n",    "        dummy_features = dummies.columns.values\n",    "        ohe_features = pd.concat([df_first, dummies], axis=1)\n",    "        ohe_features = ohe_features.drop(columns=feature_columns)\n",    "        \n",    "        # Группируем по id и sum данные после ohe\n",    "        ohe_features.groupby(\"id\")\n",    "        features = ohe_features.groupby(\"id\")[dummy_features].sum().reset_index(drop=False)\n",    "        \n",    "        # Здесь просто группируем и агрегируем \n",    "        df_second = df_second.groupby('id').sum().reset_index(drop=False)\n",    "        \n",    "        # Объединяем датафреймы обратно\n",    "        df_result = pd.merge(features, df_second, on='id')\n",    "        \n",    "        #записываем подготовленные данные в файл\n",    "        preprocessed_frames.append(df_result)\n",    "    return pd.concat(preprocessed_frames, join='inner', ignore_index=True)"   ],   "metadata": {    "collapsed": false,    "ExecuteTime": {     "end_time": "2023-12-22T10:46:29.086064Z",     "start_time": "2023-12-22T10:46:29.061461Z"    }   },   "id": "6e47eec0922e10c2"  },  {   "cell_type": "code",   "execution_count": 5,   "outputs": [    {     "data": {      "text/plain": "Transforming transactions data:   0%|          | 0/6 [00:00<?, ?it/s]",      "application/vnd.jupyter.widget-view+json": {       "version_major": 2,       "version_minor": 0,       "model_id": "4f905717a7b449099b01cfd0cf5ca581"      }     },     "metadata": {},     "output_type": "display_data"    },    {     "name": "stdout",     "output_type": "stream",     "text": [      "['train_data/train_data_0.pq', 'train_data/train_data_1.pq', 'train_data/train_data_10.pq', 'train_data/train_data_11.pq', 'train_data/train_data_2.pq', 'train_data/train_data_3.pq', 'train_data/train_data_4.pq', 'train_data/train_data_5.pq', 'train_data/train_data_6.pq', 'train_data/train_data_7.pq', 'train_data/train_data_8.pq', 'train_data/train_data_9.pq']\n"     ]    },    {     "data": {      "text/plain": "Reading dataset with pandas:   0%|          | 0/2 [00:00<?, ?it/s]",      "application/vnd.jupyter.widget-view+json": {       "version_major": 2,       "version_minor": 0,       "model_id": "b85c3022d2f740c8a60c3486de299bf1"      }     },     "metadata": {},     "output_type": "display_data"    },    {     "name": "stdout",     "output_type": "stream",     "text": [      "chunk_path train_data/train_data_0.pq\n",      "chunk_path train_data/train_data_1.pq\n",      "['train_data/train_data_0.pq', 'train_data/train_data_1.pq', 'train_data/train_data_10.pq', 'train_data/train_data_11.pq', 'train_data/train_data_2.pq', 'train_data/train_data_3.pq', 'train_data/train_data_4.pq', 'train_data/train_data_5.pq', 'train_data/train_data_6.pq', 'train_data/train_data_7.pq', 'train_data/train_data_8.pq', 'train_data/train_data_9.pq']\n"     ]    },    {     "data": {      "text/plain": "Reading dataset with pandas:   0%|          | 0/2 [00:00<?, ?it/s]",      "application/vnd.jupyter.widget-view+json": {       "version_major": 2,       "version_minor": 0,       "model_id": "03130d7d3fbd4a24b6cb3f6806ee737f"      }     },     "metadata": {},     "output_type": "display_data"    },    {     "name": "stdout",     "output_type": "stream",     "text": [      "chunk_path train_data/train_data_10.pq\n",      "chunk_path train_data/train_data_11.pq\n",      "['train_data/train_data_0.pq', 'train_data/train_data_1.pq', 'train_data/train_data_10.pq', 'train_data/train_data_11.pq', 'train_data/train_data_2.pq', 'train_data/train_data_3.pq', 'train_data/train_data_4.pq', 'train_data/train_data_5.pq', 'train_data/train_data_6.pq', 'train_data/train_data_7.pq', 'train_data/train_data_8.pq', 'train_data/train_data_9.pq']\n"     ]    },    {     "data": {      "text/plain": "Reading dataset with pandas:   0%|          | 0/2 [00:00<?, ?it/s]",      "application/vnd.jupyter.widget-view+json": {       "version_major": 2,       "version_minor": 0,       "model_id": "169a55caf18b419ca1ca00ef4d5f030b"      }     },     "metadata": {},     "output_type": "display_data"    },    {     "name": "stdout",     "output_type": "stream",     "text": [      "chunk_path train_data/train_data_2.pq\n",      "chunk_path train_data/train_data_3.pq\n",      "['train_data/train_data_0.pq', 'train_data/train_data_1.pq', 'train_data/train_data_10.pq', 'train_data/train_data_11.pq', 'train_data/train_data_2.pq', 'train_data/train_data_3.pq', 'train_data/train_data_4.pq', 'train_data/train_data_5.pq', 'train_data/train_data_6.pq', 'train_data/train_data_7.pq', 'train_data/train_data_8.pq', 'train_data/train_data_9.pq']\n"     ]    },    {     "data": {      "text/plain": "Reading dataset with pandas:   0%|          | 0/2 [00:00<?, ?it/s]",      "application/vnd.jupyter.widget-view+json": {       "version_major": 2,       "version_minor": 0,       "model_id": "1fddbfee7efe4f75903959f4a4d796eb"      }     },     "metadata": {},     "output_type": "display_data"    },    {     "name": "stdout",     "output_type": "stream",     "text": [      "chunk_path train_data/train_data_4.pq\n",      "chunk_path train_data/train_data_5.pq\n",      "['train_data/train_data_0.pq', 'train_data/train_data_1.pq', 'train_data/train_data_10.pq', 'train_data/train_data_11.pq', 'train_data/train_data_2.pq', 'train_data/train_data_3.pq', 'train_data/train_data_4.pq', 'train_data/train_data_5.pq', 'train_data/train_data_6.pq', 'train_data/train_data_7.pq', 'train_data/train_data_8.pq', 'train_data/train_data_9.pq']\n"     ]    },    {     "data": {      "text/plain": "Reading dataset with pandas:   0%|          | 0/2 [00:00<?, ?it/s]",      "application/vnd.jupyter.widget-view+json": {       "version_major": 2,       "version_minor": 0,       "model_id": "650e9ea62b13486ca1b00c48ad23a8e4"      }     },     "metadata": {},     "output_type": "display_data"    },    {     "name": "stdout",     "output_type": "stream",     "text": [      "chunk_path train_data/train_data_6.pq\n",      "chunk_path train_data/train_data_7.pq\n",      "['train_data/train_data_0.pq', 'train_data/train_data_1.pq', 'train_data/train_data_10.pq', 'train_data/train_data_11.pq', 'train_data/train_data_2.pq', 'train_data/train_data_3.pq', 'train_data/train_data_4.pq', 'train_data/train_data_5.pq', 'train_data/train_data_6.pq', 'train_data/train_data_7.pq', 'train_data/train_data_8.pq', 'train_data/train_data_9.pq']\n"     ]    },    {     "data": {      "text/plain": "Reading dataset with pandas:   0%|          | 0/2 [00:00<?, ?it/s]",      "application/vnd.jupyter.widget-view+json": {       "version_major": 2,       "version_minor": 0,       "model_id": "ddc51e356d8f4481a1e6e748267c47e1"      }     },     "metadata": {},     "output_type": "display_data"    },    {     "name": "stdout",     "output_type": "stream",     "text": [      "chunk_path train_data/train_data_8.pq\n",      "chunk_path train_data/train_data_9.pq\n"     ]    }   ],   "source": [    "data = prepare_transactions_dataset(path, num_parts_to_preprocess_at_once=2, num_parts_total=12)"   ],   "metadata": {    "collapsed": false,    "ExecuteTime": {     "end_time": "2023-12-22T10:49:37.340478Z",     "start_time": "2023-12-22T10:46:29.063940Z"    }   },   "id": "bd0810eee29e8111"  },  {   "cell_type": "code",   "execution_count": 6,   "outputs": [    {     "data": {      "text/plain": "   id  pre_since_opened_0  pre_since_opened_1  pre_since_opened_2  \\\n0   0                   0                   1                   1   \n1   1                   0                   0                   1   \n2   2                   1                   0                   0   \n3   3                   0                   3                   1   \n4   4                   0                   0                   0   \n\n   pre_since_opened_3  pre_since_opened_4  pre_since_opened_5  \\\n0                   1                   1                   2   \n1                   0                   0                   0   \n2                   0                   0                   0   \n3                   0                   2                   1   \n4                   0                   0                   0   \n\n   pre_since_opened_6  pre_since_opened_7  pre_since_opened_8  ...  \\\n0                   0                   1                   0  ...   \n1                   0                   1                   2  ...   \n2                   0                   0                   0  ...   \n3                   3                   0                   0  ...   \n4                   0                   0                   0  ...   \n\n   is_zero_loans530  is_zero_loans3060  is_zero_loans6090  is_zero_loans90  \\\n0                10                 10                 10               10   \n1                10                 12                 12               11   \n2                 2                  2                  2                3   \n3                15                 15                 15               15   \n4                 1                  1                  1                1   \n\n   is_zero_util  is_zero_over2limit  is_zero_maxover2limit  pclose_flag  \\\n0             6                   9                      9            1   \n1            10                  12                     11            1   \n2             1                   3                      2            2   \n3             8                  14                     14            5   \n4             1                   1                      1            1   \n\n   fclose_flag  no_delinquencies  \n0            2                 9  \n1            2                 6  \n2            2                 2  \n3            6                15  \n4            1                 1  \n\n[5 rows x 398 columns]",      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>id</th>\n      <th>pre_since_opened_0</th>\n      <th>pre_since_opened_1</th>\n      <th>pre_since_opened_2</th>\n      <th>pre_since_opened_3</th>\n      <th>pre_since_opened_4</th>\n      <th>pre_since_opened_5</th>\n      <th>pre_since_opened_6</th>\n      <th>pre_since_opened_7</th>\n      <th>pre_since_opened_8</th>\n      <th>...</th>\n      <th>is_zero_loans530</th>\n      <th>is_zero_loans3060</th>\n      <th>is_zero_loans6090</th>\n      <th>is_zero_loans90</th>\n      <th>is_zero_util</th>\n      <th>is_zero_over2limit</th>\n      <th>is_zero_maxover2limit</th>\n      <th>pclose_flag</th>\n      <th>fclose_flag</th>\n      <th>no_delinquencies</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n      <td>2</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>...</td>\n      <td>10</td>\n      <td>10</td>\n      <td>10</td>\n      <td>10</td>\n      <td>6</td>\n      <td>9</td>\n      <td>9</td>\n      <td>1</td>\n      <td>2</td>\n      <td>9</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>2</td>\n      <td>...</td>\n      <td>10</td>\n      <td>12</td>\n      <td>12</td>\n      <td>11</td>\n      <td>10</td>\n      <td>12</td>\n      <td>11</td>\n      <td>1</td>\n      <td>2</td>\n      <td>6</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>2</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>...</td>\n      <td>2</td>\n      <td>2</td>\n      <td>2</td>\n      <td>3</td>\n      <td>1</td>\n      <td>3</td>\n      <td>2</td>\n      <td>2</td>\n      <td>2</td>\n      <td>2</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>3</td>\n      <td>0</td>\n      <td>3</td>\n      <td>1</td>\n      <td>0</td>\n      <td>2</td>\n      <td>1</td>\n      <td>3</td>\n      <td>0</td>\n      <td>0</td>\n      <td>...</td>\n      <td>15</td>\n      <td>15</td>\n      <td>15</td>\n      <td>15</td>\n      <td>8</td>\n      <td>14</td>\n      <td>14</td>\n      <td>5</td>\n      <td>6</td>\n      <td>15</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>4</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>...</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n    </tr>\n  </tbody>\n</table>\n<p>5 rows × 398 columns</p>\n</div>"     },     "execution_count": 6,     "metadata": {},     "output_type": "execute_result"    }   ],   "source": [    "data.head()"   ],   "metadata": {    "collapsed": false,    "ExecuteTime": {     "end_time": "2023-12-22T10:49:37.401250Z",     "start_time": "2023-12-22T10:49:37.335121Z"    }   },   "id": "81557a0334f81cdb"  },  {   "cell_type": "code",   "execution_count": 7,   "outputs": [    {     "data": {      "text/plain": "(3000000, 398)"     },     "execution_count": 7,     "metadata": {},     "output_type": "execute_result"    }   ],   "source": [    "data.shape"   ],   "metadata": {    "collapsed": false,    "ExecuteTime": {     "end_time": "2023-12-22T10:49:37.402788Z",     "start_time": "2023-12-22T10:49:37.345304Z"    }   },   "id": "d0a0577354157fab"  },  {   "cell_type": "code",   "execution_count": 8,   "outputs": [    {     "data": {      "text/plain": "0"     },     "execution_count": 8,     "metadata": {},     "output_type": "execute_result"    }   ],   "source": [    "data.isna().sum().sum()"   ],   "metadata": {    "collapsed": false,    "ExecuteTime": {     "end_time": "2023-12-22T10:49:38.014245Z",     "start_time": "2023-12-22T10:49:37.348229Z"    }   },   "id": "d27f29dada1788e7"  },  {   "cell_type": "code",   "execution_count": 9,   "outputs": [    {     "name": "stdout",     "output_type": "stream",     "text": [      "Объединение файлов завершено.\n",      "Сохранение файла завершено.\n"     ]    }   ],   "source": [    "# Объединяем с целевой переменной\n",    "df = pd.merge(data, target_df[['id', 'flag']], on='id', how='left')\n",    "df = df.drop('id', axis=1)\n",    "print(f\"Объединение файлов завершено.\")\n",    "parquet_file_path = 'dataset_full_ohe.parquet'\n",    "\n",    "# Преобразуем DataFrame в таблицу pyarrow\n",    "table = pa.Table.from_pandas(df)\n",    "\n",    "# Сохраняем таблицу в формате Parquet\n",    "pq.write_table(table, parquet_file_path)\n",    "print(f\"Сохранение файла завершено.\")"   ],   "metadata": {    "collapsed": false,    "ExecuteTime": {     "end_time": "2023-12-22T10:50:06.914244Z",     "start_time": "2023-12-22T10:49:38.006127Z"    }   },   "id": "e187a99687eaa9b2"  } ], "metadata": {  "kernelspec": {   "display_name": "Python 3",   "language": "python",   "name": "python3"  },  "language_info": {   "codemirror_mode": {    "name": "ipython",    "version": 2   },   "file_extension": ".py",   "mimetype": "text/x-python",   "name": "python",   "nbconvert_exporter": "python",   "pygments_lexer": "ipython2",   "version": "2.7.6"  } }, "nbformat": 4, "nbformat_minor": 5}